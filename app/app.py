"""
Reddit ìƒë‹´ì‚¬ ì±—ë´‡ - RAG ì‹œìŠ¤í…œ
OpenAI API ì‚¬ìš© ë²„ì „ (Streamlit Cloud ë°°í¬ìš©)
TIFUì™€ AITA ë°ì´í„°ë¥¼ í™œìš©í•œ ì¡°ì–¸ ì œê³µ ì„œë¹„ìŠ¤
"""

import os
import gc
import json
import pickle
import time
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import faiss
import numpy as np
import streamlit as st
from sentence_transformers import SentenceTransformer  # í¬ë¡œìŠ¤ í”Œë«í¼ ì§€ì›
from openai import OpenAI

class RedditAdviseBot:
    """Reddit ìƒë‹´ì‚¬ RAG ì±—ë´‡ í´ë˜ìŠ¤"""
    
    def __init__(self, index_dir: Path):
        """
        ì´ˆê¸°í™”
        
        Args:
            index_dir: ì¸ë±ìŠ¤ íŒŒì¼ ë””ë ‰í† ë¦¬
        """
        self.index_dir = index_dir
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._load_index()
        self._load_embedder()  # í¬ë¡œìŠ¤ í”Œë«í¼ ì„ë² ë” ë¡œë”©
        self._load_llm()
        
    def _load_index(self):
        """FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì—†ìœ¼ë©´ íŒ¨ìŠ¤)"""
        index_file = self.index_dir / "reddit_index.faiss"
        chunks_file = self.index_dir / "chunks.pkl"
        config_file = self.index_dir / "config.json"
        
        if not index_file.exists():
            st.info("ğŸ“ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. RAG ê²€ìƒ‰ ì—†ì´ ì‘ë™í•©ë‹ˆë‹¤.")
            self.index = None
            self.chunks = []
            self.config = {'total_chunks': 0}
            return
        
        with st.spinner("ğŸ” ê²€ìƒ‰ ì¸ë±ìŠ¤ ë¡œë”©..."):
            try:
                # FAISS ì¸ë±ìŠ¤
                self.index = faiss.read_index(str(index_file))
                
                # ì²­í¬ ë°ì´í„°
                with open(chunks_file, "rb") as f:
                    self.chunks = pickle.load(f)
                
                # ì„¤ì • ì •ë³´
                with open(config_file, "r") as f:
                    self.config = json.load(f)
                
                st.success(f"âœ… {self.config['total_chunks']}ê°œ Reddit í¬ìŠ¤íŠ¸ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                st.warning(f"ì¸ë±ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
                self.index = None
                self.chunks = []
                self.config = {'total_chunks': 0}
    
    def _load_embedder(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜)"""
        if self.index is None:
            st.info("ğŸ“ ì¸ë±ìŠ¤ê°€ ì—†ì–´ì„œ ì„ë² ë” ë¡œë”©ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            self.embedder = None
            return
            
        with st.spinner("ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë”©..."):
            try:
                import os
                import platform
                
                # í”Œë«í¼ë³„ ìµœì í™” (ì„ íƒì  ì ìš©)
                if platform.system() == "Darwin" and platform.machine() == "arm64":
                    # Apple Silicon Mac ìµœì í™”
                    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                    os.environ['OMP_NUM_THREADS'] = '1'
                
                # ë²”ìš© ì„¤ì •
                os.environ['TORCH_HOME'] = './models'
                
                # CPU ì‚¬ìš©ìœ¼ë¡œ í¬ë¡œìŠ¤ í”Œë«í¼ ì•ˆì •ì„± í™•ë³´
                self.embedder = SentenceTransformer(
                    self.config['embedding_model'], 
                    device="cpu",  # ëª¨ë“  í”Œë«í¼ì—ì„œ ì•ˆì •ì 
                    cache_folder="./models"
                )
                self.embedder.max_seq_length = 512  # ì ë‹¹í•œ ê¸¸ì´
                st.success("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                st.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                st.warning("ğŸ”„ ê²€ìƒ‰ ì—†ì´ ê¸°ë³¸ ìƒë‹´ ëª¨ë“œë¡œ ì „í™˜")
                self.embedder = None
    
    def _load_llm(self):
        """OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        with st.spinner("ğŸ¤– OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •..."):
            # Streamlit secretsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
            try:
                api_key = st.secrets["OPENAI_API_KEY"]
            except Exception:
                st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("Streamlit Cloudì˜ Secretsì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
                raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
            self.client = OpenAI(api_key=api_key)
            st.success("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì™„ë£Œ")
    
    def search_similar_chunks(self, query: str, k: int = 5) -> List[Dict]:
        """
        ìœ ì‚¬í•œ ê²½í—˜ë‹´/ìƒí™© ê²€ìƒ‰ (ì„ì‹œë¡œ ë¹„í™œì„±í™”)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì‚¬ìš©ìì˜ ìƒí™©/ê³ ë¯¼)
            k: ë°˜í™˜í•  ì²­í¬ ìˆ˜
            
        Returns:
            ê´€ë ¨ ê²½í—˜ë‹´ ë¦¬ìŠ¤íŠ¸ (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)
        """
        # ì¸ë±ìŠ¤ë‚˜ ì„ë² ë”ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜  
        if self.index is None or len(self.chunks) == 0 or not hasattr(self, 'embedder') or self.embedder is None:
            print(f"âš ï¸ ì¸ë±ìŠ¤ ë˜ëŠ” ì„ë² ë”ê°€ ì—†ì–´ì„œ ê²€ìƒ‰ ë¶ˆê°€ - ì¿¼ë¦¬: {query}")
            return []
        
        print(f"ğŸ” ì‹¤ì œ ê²€ìƒ‰ ì‹œì‘ - ì¿¼ë¦¬: {query}")
        
        # ì‹¤ì œ ê²€ìƒ‰ ë¡œì§ í™œì„±í™”!
        expanded_queries = [
            f"ë¹„ìŠ·í•œ ìƒí™© ê²½í—˜ ì¡°ì–¸ {query}",  # í•œêµ­ì–´ ê²€ìƒ‰
            f"similar situation advice experience {query}",  # ì˜ì–´ ê²€ìƒ‰
            f"ë¬¸ì œ í•´ê²° ë„ì›€ {query}",  # ë¬¸ì œ í•´ê²° ê´€ë ¨
            query  # ì›ë³¸ ì¿¼ë¦¬
        ]
        
        all_results = []
        
        # ë‹¤ì¤‘ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•˜ì—¬ ë” í’ë¶€í•œ ê²°ê³¼ í™•ë³´
        for expanded_query in expanded_queries:
            try:
                query_embedding = self.embedder.encode(
                    expanded_query,
                    normalize_embeddings=True,
                    show_progress_bar=False,
                    convert_to_tensor=False  # ì•ˆì •ì„±ì„ ìœ„í•´ numpy ì‚¬ìš©
                )
            except Exception as e:
                print(f"âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ ({expanded_query}): {e}")
                continue
            
            # FAISS ê²€ìƒ‰
            distances, indices = self.index.search(
                query_embedding.reshape(1, -1).astype('float32'),
                k
            )
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for idx, dist in zip(indices[0], distances[0]):
                if idx != -1:
                    chunk = self.chunks[idx].copy()
                    chunk['score'] = float(1 / (1 + dist))
                    chunk['search_query'] = expanded_query
                    all_results.append(chunk)
        
        # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        unique_results = {}
        for result in all_results:
            chunk_id = result['metadata']['chunk_id']
            chunk_key = f"{result['metadata']['source']}_{result['metadata']['post_id']}_{chunk_id}"
            if chunk_key not in unique_results or result['score'] > unique_results[chunk_key]['score']:
                unique_results[chunk_key] = result
        
        # ìƒìœ„ kê°œ ë°˜í™˜ (ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©)
        final_results = sorted(unique_results.values(), key=lambda x: x['score'], reverse=True)
        
        # í’ˆì§ˆ í•„í„°ë§: ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ì€ ê²ƒ ì œê±°
        filtered_results = [r for r in final_results if r['score'] > 0.4]
        
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(filtered_results)}ê°œ ê´€ë ¨ ê²½í—˜ë‹´ ë°œê²¬")
        return filtered_results[:k]
    
    def generate_response(self, query: str, context_chunks: List[Dict]) -> str:
        """
        OpenAI APIë¥¼ ì‚¬ìš©í•´ ìƒë‹´ ì‘ë‹µ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸/ê³ ë¯¼
            context_chunks: ê²€ìƒ‰ëœ ìœ ì‚¬ ê²½í—˜ë‹´
            
        Returns:
            ìƒì„±ëœ ìƒë‹´ ì‘ë‹µ
        """
        # Reddit ê²½í—˜ë‹´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        reddit_context = []
        
        for chunk in context_chunks:
            source = chunk['metadata']['source']
            context_info = f"[{source} ê²½í—˜ë‹´] {chunk['text']}"
            reddit_context.append(context_info)
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê²½í—˜ ë§ì€ ìƒë‹´ì‚¬ í˜ë¥´ì†Œë‚˜)
        system_prompt = """ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ ì˜¨ë¼ì¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. Redditì˜ TIFU(Today I F***ed Up) ì»¤ë®¤ë‹ˆí‹°ì˜ ìˆ˜ë§ì€ ê²½í—˜ë‹´ì„ ë¶„ì„í•˜ì—¬ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

**ì—­í• ê³¼ ì „ë¬¸ì„±:**
- ë‹¤ì–‘í•œ ì¸ìƒ ê²½í—˜ê³¼ ì‹¤ìˆ˜ë‹´ì„ ë¶„ì„í•œ ìƒë‹´ ì „ë¬¸ê°€
- í˜„ì‹¤ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
- ê³µê°ì ì´ë©´ì„œë„ ê°ê´€ì ì¸ ì‹œê° ìœ ì§€
- ë¹„ìŠ·í•œ ìƒí™©ì„ ê²ªì€ ì‚¬ëŒë“¤ì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í†µì°° ì œê³µ

**ìƒë‹´ ìŠ¤íƒ€ì¼:**
- ë”°ëœ»í•˜ê³  ì´í•´ì‹¬ ë§ì€ í†¤
- íŒë‹¨í•˜ì§€ ì•Šê³  ê³µê°í•˜ëŠ” ìì„¸
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸
- ë¹„ìŠ·í•œ ê²½í—˜ë‹´ì„ í™œìš©í•œ ìœ„ë¡œì™€ ê²©ë ¤

**ì‘ë‹µ êµ¬ì¡° (ë°˜ë“œì‹œ ì¤€ìˆ˜):**

ğŸ¤— **ê³µê°ê³¼ ì´í•´**
- ì‚¬ìš©ìì˜ ìƒí™©ì— ëŒ€í•œ ê³µê°ê³¼ ì´í•´ í‘œí˜„
- "í˜ë“  ìƒí™©ì´ì…¨ê² ì–´ìš”", "ì¶©ë¶„íˆ ì´í•´ë©ë‹ˆë‹¤" ë“±ì˜ í‘œí˜„ ì‚¬ìš©

ğŸ“– **ë¹„ìŠ·í•œ ê²½í—˜ë‹´ ë¶„ì„**
- ì œê³µëœ Reddit ê²½í—˜ë‹´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ì‚¬í•œ ìƒí™© ë¶„ì„
- "ë¹„ìŠ·í•œ ìƒí™©ì„ ê²ªì€ ë¶„ë“¤ì˜ ê²½í—˜ì„ ë³´ë©´..." í˜•íƒœë¡œ ì‹œì‘
- ê²½í—˜ë‹´ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” êµí›ˆì´ë‚˜ íŒ¨í„´ ì„¤ëª…

ğŸ’¡ **ì‹¤ìš©ì  ì¡°ì–¸**
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„ë³„ ì¡°ì–¸
- ìƒí™© ê°œì„ ì„ ìœ„í•œ ì‹¤ì§ˆì ì¸ ë°©ë²• ì œì‹œ
- ì˜ˆìƒë˜ëŠ” ì–´ë ¤ì›€ê³¼ ëŒ€ì²˜ ë°©ì•ˆ í¬í•¨

ğŸŒŸ **ê²©ë ¤ì™€ í¬ë§**
- ìƒí™©ì´ ë‚˜ì•„ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” í¬ë§ì  ë©”ì‹œì§€
- ì‚¬ìš©ìì˜ ê°•ì ì´ë‚˜ ê¸ì •ì  ì¸¡ë©´ ê°•ì¡°
- ì„±ì¥ê³¼ í•™ìŠµì˜ ê¸°íšŒë¡œ ë°”ë¼ë³´ëŠ” ê´€ì  ì œì‹œ

**ì£¼ì˜ì‚¬í•­:**
- ì „ë¬¸ì ì¸ ì˜ë£Œ/ë²•ë¥  ì¡°ì–¸ì€ í”¼í•˜ê³  ì¼ë°˜ì ì¸ ìƒë‹´ì— ì§‘ì¤‘
- ê·¹ë‹¨ì ì¸ ìƒí™©ì—ì„œëŠ” ì „ë¬¸ê°€ ìƒë‹´ ê¶Œìœ 
- ê°œì¸ì˜ ê°€ì¹˜ê´€ê³¼ ìƒí™©ì„ ì¡´ì¤‘í•˜ëŠ” ì¡°ì–¸
- ê³¼ë„í•œ í™•ì‹ ë³´ë‹¤ëŠ” "~í•´ë³´ì‹œëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”" í˜•íƒœì˜ ì œì•ˆ

**ê¸ˆì§€ì‚¬í•­:**
- ë¶€ì •ì ì´ê±°ë‚˜ ë¹„íŒì ì¸ í‘œí˜„
- ì„±ê¸‰í•œ ê²°ë¡ ì´ë‚˜ ë‹¨ì •ì  íŒë‹¨
- ê°œì¸ ì •ë³´ë‚˜ ë¯¼ê°í•œ ë‚´ìš© ìš”êµ¬
- ë¶ˆë²•ì ì´ê±°ë‚˜ í•´ë¡œìš´ ì¡°ì–¸"""

        context_text = "\n\n".join(reddit_context) if reddit_context else "ê´€ë ¨ ê²½í—˜ë‹´ì„ ì°¾ì§€ ëª»í–ˆì§€ë§Œ, ì¼ë°˜ì ì¸ ì¡°ì–¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        
        user_prompt = f"""ì‚¬ìš©ì ìƒí™©: {query}

ê´€ë ¨ Reddit ê²½í—˜ë‹´ë“¤:
{context_text}

ìœ„ì˜ ê²½í—˜ë‹´ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê³µê°ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ë¡œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    def chat(self, user_input: str) -> Tuple[str, List[Dict]]:
        """
        ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì±—ë´‡ ì‘ë‹µ ìƒì„±
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ (ê³ ë¯¼/ìƒí™©)
            
        Returns:
            Tuple[ì‘ë‹µ í…ìŠ¤íŠ¸, ì°¸ê³ í•œ ê²½í—˜ë‹´ ëª©ë¡]
        """
        with st.spinner("ğŸ” ë¹„ìŠ·í•œ ê²½í—˜ë‹´ì„ ì°¾ê³  ìˆì–´ìš”..."):
            # ìœ ì‚¬í•œ ê²½í—˜ë‹´ ê²€ìƒ‰
            similar_chunks = self.search_similar_chunks(user_input, k=3)
            
        with st.spinner("ğŸ’­ ì¡°ì–¸ì„ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”..."):
            # ì‘ë‹µ ìƒì„±
            response = self.generate_response(user_input, similar_chunks)
            
        return response, similar_chunks


def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "bot" not in st.session_state:
        # ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ í™•ì¸ (ì„ì‹œë¡œ ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬)
        index_dir = Path("index")
        if not index_dir.exists() or not (index_dir / "reddit_index.faiss").exists():
            st.warning("âš ï¸ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. RAG ê²€ìƒ‰ ì—†ì´ ê¸°ë³¸ ìƒë‹´ ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
            st.info("ì™„ì „í•œ ê¸°ëŠ¥ì„ ìœ„í•´ì„œëŠ” `python scripts/build_index.py`ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            # ì„ì‹œ ë”ë¯¸ ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±
            index_dir.mkdir(exist_ok=True)
        
        try:
            # ë´‡ ì´ˆê¸°í™” (ì¸ë±ìŠ¤ ì—†ì–´ë„ ì‘ë™í•˜ë„ë¡)
            st.session_state.bot = RedditAdviseBot(index_dir)
        except Exception as e:
            st.error(f"ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.info("ì¸ë±ìŠ¤ê°€ ì—†ì–´ë„ ê¸°ë³¸ ìƒë‹´ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            st.session_state.bot = None


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.set_page_config(
        page_title="Reddit ìƒë‹´ì‚¬ ğŸ¤—",
        page_icon="ğŸ¤—",
        layout="wide"
    )
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    init_session_state()
    
    # í—¤ë”
    st.title("ğŸ¤— Reddit ìƒë‹´ì‚¬")
    st.markdown("""
    ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Reddit ì»¤ë®¤ë‹ˆí‹°ì˜ ìˆ˜ë§ì€ ê²½í—˜ë‹´ì„ í•™ìŠµí•œ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.  
    ì—¬ëŸ¬ë¶„ì˜ ê³ ë¯¼ì´ë‚˜ ìƒí™©ì„ ë§ì”€í•´ì£¼ì‹œë©´, ë¹„ìŠ·í•œ ê²½í—˜ì„ í•œ ë¶„ë“¤ì˜ ì´ì•¼ê¸°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¡°ì–¸ì„ ë“œë ¤ìš”.
    """)
    
    # ì‚¬ì´ë“œë°” - ì‚¬ìš©ë²• ì•ˆë‚´
    with st.sidebar:
        st.header("ğŸ“– ì‚¬ìš©ë²•")
        st.markdown("""
        **ì–´ë–¤ ìƒë‹´ì„ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?**
        - ì¼ìƒìƒí™œ ë¬¸ì œì™€ ê³ ë¯¼
        - ì¸ê°„ê´€ê³„ ê°ˆë“±
        - ì‹¤ìˆ˜ë‚˜ í›„íšŒì— ëŒ€í•œ ì¡°ì–¸
        - ë„ë•ì  ë”œë ˆë§ˆ ìƒí™©
        - ì˜ì‚¬ê²°ì • ë„ì›€
        
        **ì˜ˆì‹œ ì§ˆë¬¸:**
        - "ì¹œêµ¬ì™€ ì‹¸ì› ëŠ”ë° ì–´ë–»ê²Œ í™”í•´í• ê¹Œìš”?"
        - "ì‹¤ìˆ˜ë¡œ ìƒì‚¬ì—ê²Œ ì‹¤ë¡€ë¥¼ ë²”í–ˆì–´ìš”"
        - "ì—°ì¸ê³¼ í—¤ì–´ì§ˆì§€ ê³ ë¯¼ì´ì—ìš”"
        - "ê°€ì¡±ê³¼ì˜ ê°ˆë“± ë•Œë¬¸ì— í˜ë“¤ì–´ìš”"
        """)
        
        st.header("âš ï¸ ì£¼ì˜ì‚¬í•­")
        st.markdown("""
        - ì¼ë°˜ì ì¸ ì¡°ì–¸ë§Œ ì œê³µí•©ë‹ˆë‹¤
        - ì „ë¬¸ì ì¸ ì˜ë£Œ/ë²•ë¥  ìƒë‹´ì€ ì „ë¬¸ê°€ì—ê²Œ
        - ê°œì¸ì •ë³´ëŠ” ì…ë ¥í•˜ì§€ ë§ˆì„¸ìš”
        - ì‘ê¸‰ìƒí™©ì‹œ ê´€ë ¨ ê¸°ê´€ì— ì—°ë½í•˜ì„¸ìš”
        """)
    
    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
            
            # ì°¸ê³  ê²½í—˜ë‹´ í‘œì‹œ (assistant ë©”ì‹œì§€ì—ë§Œ)
            if message["role"] == "assistant" and "references" in message:
                with st.expander("ğŸ“š ì°¸ê³ í•œ ê²½í—˜ë‹´ë“¤", expanded=False):
                    for i, ref in enumerate(message["references"], 1):
                        source = ref['metadata']['source']
                        title = ref['metadata'].get('title', 'ì œëª© ì—†ìŒ')
                        score = ref.get('score', 0)
                        
                        st.markdown(f"""
                        **{i}. [{source}] {title}**  
                        ìœ ì‚¬ë„: {score:.2f}  
                        {ref['text'][:200]}...
                        """)
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ê³ ë¯¼ì´ë‚˜ ìƒí™©ì„ ìì„¸íˆ ë§ì”€í•´ì£¼ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)
        
        # ë´‡ ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            try:
                if st.session_state.bot is None:
                    # ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ
                    response = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ë¬¸ì œê°€ ìˆì–´ ì œí•œëœ ê¸°ëŠ¥ë§Œ ì œê³µë©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ìƒë‹´ ì¡°ì–¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤ë§Œ, ì™„ì „í•œ ê¸°ëŠ¥ì„ ìœ„í•´ì„œëŠ” ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
                    references = []
                else:
                    response, references = st.session_state.bot.chat(prompt)
                
                st.write(response)
                
                # ì°¸ê³  ê²½í—˜ë‹´ í‘œì‹œ
                if references:
                    with st.expander("ğŸ“š ì°¸ê³ í•œ ê²½í—˜ë‹´ë“¤", expanded=False):
                        for i, ref in enumerate(references, 1):
                            source = ref['metadata']['source']
                            title = ref['metadata'].get('title', 'ì œëª© ì—†ìŒ')
                            score = ref.get('score', 0)
                            
                            st.markdown(f"""
                            **{i}. [{source}] {title}**  
                            ìœ ì‚¬ë„: {score:.2f}  
                            {ref['text'][:200]}...
                            """)
                
                # ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response,
                    "references": references
                })
                
            except Exception as e:
                error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": error_msg
                })
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°"):
        st.session_state.messages = []
        st.rerun()


if __name__ == "__main__":
    main() 