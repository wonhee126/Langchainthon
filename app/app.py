"""
í•œë°¤ì˜ ê¿ˆí•´ëª½ ìƒë‹´ê°€ - RAG ì±—ë´‡
OpenAI API ì‚¬ìš© ë²„ì „ (Streamlit Cloud ë°°í¬ìš©)
"""

import os
import gc
import json
import pickle
import time
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import faiss
import numpy as np
import psutil
import streamlit as st
from sentence_transformers import SentenceTransformer
from openai import OpenAI

class DreamRAGBot:
    """ê¿ˆ í•´ì„ RAG ì±—ë´‡ í´ë˜ìŠ¤"""
    
    def __init__(self, index_dir: Path):
        """
        ì´ˆê¸°í™”
        
        Args:
            index_dir: ì¸ë±ìŠ¤ íŒŒì¼ ë””ë ‰í† ë¦¬
        """
        self.index_dir = index_dir
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._load_index()
        self._load_embedder()
        self._load_llm()
        
    def _load_index(self):
        """FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        with st.spinner("ğŸ” ê²€ìƒ‰ ì¸ë±ìŠ¤ ë¡œë”©..."):
            # FAISS ì¸ë±ìŠ¤
            self.index = faiss.read_index(str(self.index_dir / "dream_index.faiss"))
            
            # ì²­í¬ ë°ì´í„°
            with open(self.index_dir / "chunks.pkl", "rb") as f:
                self.chunks = pickle.load(f)
            
            # ì„¤ì • ì •ë³´
            with open(self.index_dir / "config.json", "r") as f:
                self.config = json.load(f)
            
            st.success(f"âœ… {self.config['total_chunks']}ê°œ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
    
    def _load_embedder(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        with st.spinner("ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë”©..."):
            self.embedder = SentenceTransformer(
                self.config['embedding_model'], device="cpu"
            )
            self.embedder.max_seq_length = 512
    
    def _load_llm(self):
        """OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        with st.spinner("ğŸ¤– OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •..."):
            # Streamlit secretsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
            try:
                api_key = st.secrets["OPENAI_API_KEY"]
            except Exception:
                st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.info("Streamlit Cloudì˜ Secretsì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
                raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
            self.client = OpenAI(api_key=api_key)
            st.success("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì™„ë£Œ")
    
    def search_similar_chunks(self, query: str, k: int = 5) -> List[Dict]:
        """
        ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ì²­í¬ ìˆ˜
            
        Returns:
            ê´€ë ¨ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embedder.encode(
            query,
            normalize_embeddings=True,
            show_progress_bar=False
        )
        
        # FAISS ê²€ìƒ‰
        distances, indices = self.index.search(
            query_embedding.reshape(1, -1).astype('float32'),
            k
        )
        
        # ê²°ê³¼ ì¶”ì¶œ
        results = []
        for idx, dist in zip(indices[0], distances[0]):
            if idx != -1:  # ìœ íš¨í•œ ì¸ë±ìŠ¤
                chunk = self.chunks[idx].copy()
                chunk['score'] = float(1 / (1 + dist))  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                results.append(chunk)
        
        return results
    
    def generate_response(self, query: str, context_chunks: List[Dict]) -> str:
        """
        OpenAI APIë¥¼ ì‚¬ìš©í•´ ì‘ë‹µ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            context_chunks: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            ìƒì„±ëœ ì‘ë‹µ
        """
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        freud_context = []
        who_context = []
        
        for chunk in context_chunks:
            if "freud" in chunk['metadata']['source'].lower():
                freud_context.append(chunk['text'])
            else:
                who_context.append(chunk['text'])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """ë‹¹ì‹ ì€ ê¿ˆ í•´ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
í”„ë¡œì´íŠ¸ì˜ ì •ì‹ ë¶„ì„í•™ì  ê´€ì ê³¼ WHOì˜ í˜„ëŒ€ ìˆ˜ë©´ê³¼í•™ì„ í†µí•©í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
ë‹µë³€ì€ ë°˜ë“œì‹œ ë‹¤ìŒ 3ë‹¨ê³„ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”:

â‘  <ê³ ì „ì  í•´ì„>: í”„ë¡œì´íŠ¸ ì´ë¡  ê¸°ë°˜ (ì•½ê°„ ì—„ìˆ™í•˜ê³  í•™ìˆ ì  í†¤)
â‘¡ <í˜„ëŒ€ ê³¼í•™>: WHO ìˆ˜ë©´ ê°€ì´ë“œ ê¸°ë°˜ (ê°„ê²°í•˜ê³  ì‹¤ìš©ì )  
â‘¢ <í†µí•© ì¡°ì–¸>: ë‘ ê´€ì ì„ ê²°í•©í•œ ì‹¤ì²œì  ì¡°ì–¸ (ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤)

ê° ë‹¨ê³„ëŠ” 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

        user_prompt = f"""ê¿ˆ ë‚´ìš©: {query}

í”„ë¡œì´íŠ¸ ìë£Œ:
{' '.join(freud_context[:2]) if freud_context else 'ê´€ë ¨ ìë£Œ ì—†ìŒ'}

WHO ìˆ˜ë©´ ìë£Œ:
{' '.join(who_context[:2]) if who_context else 'ê´€ë ¨ ìë£Œ ì—†ìŒ'}

ìœ„ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ 3ë‹¨ê³„ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""
        
        # OpenAI API í˜¸ì¶œ (o3 ëª¨ë¸ ê³ ì •)
        try:
            response = self.client.chat.completions.create(
                model="o3-mini",  # o3 ëª¨ë¸ ê³ ì •
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=600,
                temperature=0.7,
                top_p=0.9,
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            st.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ê¿ˆ í•´ì„ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."


def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    if 'rag_bot' not in st.session_state:
        index_dir = Path("index")
        if index_dir.exists():
            try:
                st.session_state.rag_bot = DreamRAGBot(index_dir)
            except ValueError as e:
                st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                st.stop()
        else:
            st.error("âŒ ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € `python scripts/build_index.py`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            st.stop()


def main():
    """ë©”ì¸ ì•± í•¨ìˆ˜"""
    st.set_page_config(
        page_title="í•œë°¤ì˜ ê¿ˆí•´ëª½ ìƒë‹´ê°€ ğŸŒ™",
        page_icon="ğŸ”®",
        layout="wide"
    )
    
    # í—¤ë”
    st.title("ğŸŒ™ í•œë°¤ì˜ ê¿ˆí•´ëª½ ìƒë‹´ê°€")
    st.markdown("í”„ë¡œì´íŠ¸ì˜ ì •ì‹ ë¶„ì„ê³¼ WHOì˜ ìˆ˜ë©´ê³¼í•™ì´ ë§Œë‚˜ëŠ” ê³³")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("### ğŸ’¡ ì‚¬ìš©ë²•")
        st.markdown("""
        1. ê¿ˆì˜ ë‚´ìš©ì„ ìì„¸íˆ ì…ë ¥í•˜ì„¸ìš”
        2. OpenAI o3ë¡œ ì„¸ ê°€ì§€ ê´€ì ì˜ í•´ì„ì„ ë°›ì•„ë³´ì„¸ìš”
        3. ë” ë‚˜ì€ ìˆ˜ë©´ì„ ìœ„í•œ ì¡°ì–¸ë„ í•¨ê»˜!
        """)
        
        st.markdown("---")
        
        # ëª¨ë¸ ì •ë³´ í‘œì‹œ
        st.info("ğŸ¤– ì‚¬ìš© ëª¨ë¸: OpenAI o3-mini")
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
        memory = psutil.virtual_memory()
        st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"{memory.percent:.1f}%")
        
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = []
            gc.collect()
            st.rerun()
    
    # ì„¸ì…˜ ì´ˆê¸°í™”
    init_session_state()
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar=message.get("avatar")):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì˜¤ëŠ˜ ë°¤ ê¾¼ ê¿ˆì„ ë“¤ë ¤ì£¼ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "user",
            "content": prompt,
            "avatar": "ğŸ§‘"
        })
        
        with st.chat_message("user", avatar="ğŸ§‘"):
            st.markdown(prompt)
        
        # ë´‡ ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant", avatar="ğŸ”®"):
            with st.spinner("ê¿ˆì„ í•´ì„í•˜ëŠ” ì¤‘..."):
                start_time = time.time()
                
                # RAG ê²€ìƒ‰
                relevant_chunks = st.session_state.rag_bot.search_similar_chunks(prompt, k=6)
                
                # ì‘ë‹µ ìƒì„±
                response = st.session_state.rag_bot.generate_response(prompt, relevant_chunks)
                
                elapsed_time = time.time() - start_time
                
                # ì‘ë‹µ í‘œì‹œ
                st.markdown(response)
                
                # ì„±ëŠ¥ ì •ë³´ (ì¶•ì†Œ ê°€ëŠ¥)
                with st.expander(f"ğŸ” ë¶„ì„ ì •ë³´ ({elapsed_time:.1f}ì´ˆ)"):
                    st.markdown("**ì°¸ê³  ìë£Œ:**")
                    for i, chunk in enumerate(relevant_chunks[:3], 1):
                        source = chunk['metadata']['source']
                        st.markdown(f"{i}. {source} - ìœ ì‚¬ë„: {chunk['score']:.2f}")
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
        
        # ë´‡ ë©”ì‹œì§€ ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "avatar": "ğŸ”®"
        })


if __name__ == "__main__":
    main() 